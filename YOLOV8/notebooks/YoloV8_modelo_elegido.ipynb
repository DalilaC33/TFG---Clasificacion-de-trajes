{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9712b50",
   "metadata": {},
   "source": [
    "#### Entrenamiento Modelo Final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab8e27",
   "metadata": {},
   "source": [
    "Sumar datos entrenamiento + validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c51de4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset combinado en 'train_full/' exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Ruta base del dataset\n",
    "base_path = r\"C:\\\\Users\\\\dalil\\\\Desktop\\\\Tesis_2025\\\\TFG---Clasificacion-de-trajes\\\\YOLOV8\\\\dataset\"\n",
    "\n",
    "# Rutas de origen y destino\n",
    "train_dir = os.path.join(base_path, \"train\")\n",
    "val_dir = os.path.join(base_path, \"val\")\n",
    "train_full_dir = os.path.join(base_path, \"train_full\")\n",
    "\n",
    "# Crear carpetas de clases en train_full y copiar archivos\n",
    "def merge_folders(src_dirs, dest_dir):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    for src in src_dirs:\n",
    "        for class_name in os.listdir(src):\n",
    "            class_src = os.path.join(src, class_name)\n",
    "            class_dest = os.path.join(dest_dir, class_name)\n",
    "            os.makedirs(class_dest, exist_ok=True)\n",
    "\n",
    "            for file_name in os.listdir(class_src):\n",
    "                src_file = os.path.join(class_src, file_name)\n",
    "                dest_file = os.path.join(class_dest, file_name)\n",
    "\n",
    "                # Evitar sobrescribir archivos con el mismo nombre\n",
    "                if os.path.exists(dest_file):\n",
    "                    base, ext = os.path.splitext(file_name)\n",
    "                    i = 1\n",
    "                    while os.path.exists(dest_file):\n",
    "                        new_file_name = f\"{base}_{i}{ext}\"\n",
    "                        dest_file = os.path.join(class_dest, new_file_name)\n",
    "                        i += 1\n",
    "\n",
    "                shutil.copy2(src_file, dest_file)\n",
    "\n",
    "# Ejecutar la fusión\n",
    "merge_folders([train_dir, val_dir], train_full_dir)\n",
    "\n",
    "print(\"✅ Dataset combinado en 'train_full/' exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a0395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.109 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.67  Python-3.11.9 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=C:\\\\Users\\\\dalil\\\\Desktop\\\\Tesis_2025\\\\TFG---Clasificacion-de-trajes\\\\YOLOV8\\\\dataset, epochs=20, time=None, patience=10, batch=16, imgsz=256, save=True, save_period=-1, cache=False, device=None, workers=8, project=C:\\\\Users\\\\dalil\\\\Desktop\\\\Tesis_2025\\\\TFG---Clasificacion-de-trajes\\\\YOLOV8\\\\modelo8, name=train2, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.2, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.1, momentum=0.9, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\modelo8\\train2\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\dataset\\train... found 1812 images in 4 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\dataset\\val... found 414 images in 4 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\dataset\\test... found 158 images in 4 classes  \n",
      "Overriding model.yaml nc=1000 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
      "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
      "  9                  -1  1    990724  ultralytics.nn.modules.head.Classify         [768, 4]                      \n",
      "YOLOv8m-cls summary: 141 layers, 15,777,460 parameters, 15,777,460 gradients, 41.9 GFLOPs\n",
      "Transferred 228/230 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\modelo8\\train2', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\dataset\\train... 1812 images, 0 corrupt: 100%|██████████| 1812/1812 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\dataset\\val... 414 images, 0 corrupt: 100%|██████████| 414/414 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 256 train, 256 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\modelo8\\train2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      1.058          4        256: 100%|██████████| 114/114 [07:15<00:00,  3.82s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:55<00:00,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.795          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G     0.5881          4        256: 100%|██████████| 114/114 [07:22<00:00,  3.89s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:56<00:00,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.872          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G      0.423          4        256: 100%|██████████| 114/114 [17:36<00:00,  9.27s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:53<00:00,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.899          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G     0.3879          4        256: 100%|██████████| 114/114 [07:20<00:00,  3.86s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:55<00:00,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.932          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G     0.2681          4        256: 100%|██████████| 114/114 [07:12<00:00,  3.79s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:55<00:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.964          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G     0.2061          4        256: 100%|██████████| 114/114 [52:47<00:00, 27.78s/it]  \n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [01:15<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.983          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G     0.1535          4        256: 100%|██████████| 114/114 [09:08<00:00,  4.81s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [01:05<00:00,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.995          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      0.172          4        256: 100%|██████████| 114/114 [08:51<00:00,  4.66s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [01:04<00:00,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.995          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G     0.1292          4        256: 100%|██████████| 114/114 [08:54<00:00,  4.68s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [01:04<00:00,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.998          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      0.124          4        256: 100%|██████████| 114/114 [08:39<00:00,  4.56s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [01:03<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G     0.1168          4        256: 100%|██████████| 114/114 [08:35<00:00,  4.52s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [01:02<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.998          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G    0.08253          4        256: 100%|██████████| 114/114 [08:36<00:00,  4.53s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [01:03<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G    0.09188          4        256: 100%|██████████| 114/114 [40:11<00:00, 21.16s/it]  \n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:53<00:00,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.995          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G    0.09504          4        256: 100%|██████████| 114/114 [07:16<00:00,  3.83s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:54<00:00,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.998          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G    0.09025          4        256: 100%|██████████| 114/114 [07:10<00:00,  3.78s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:55<00:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.998          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G    0.06928          4        256: 100%|██████████| 114/114 [1:03:58<00:00, 33.67s/it] \n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:55<00:00,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.998          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G    0.06251          4        256: 100%|██████████| 114/114 [07:12<00:00,  3.79s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:53<00:00,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.998          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G    0.07218          4        256: 100%|██████████| 114/114 [07:05<00:00,  3.73s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:54<00:00,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.998          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G     0.0514          4        256: 100%|██████████| 114/114 [10:28<00:00,  5.51s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:53<00:00,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.998          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G    0.06877          4        256: 100%|██████████| 114/114 [07:11<00:00,  3.79s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:53<00:00,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.998          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 5.379 hours.\n",
      "Optimizer stripped from C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\modelo8\\train2\\weights\\last.pt, 31.7MB\n",
      "Optimizer stripped from C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\modelo8\\train2\\weights\\best.pt, 31.7MB\n",
      "\n",
      "Validating C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\modelo8\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.67  Python-3.11.9 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15,767,780 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\dataset\\train... found 1812 images in 4 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\dataset\\val... found 414 images in 4 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\dataset\\test... found 158 images in 4 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:   8%|▊         | 1/13 [00:03<00:47,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  15%|█▌        | 2/13 [00:07<00:40,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  23%|██▎       | 3/13 [00:12<00:41,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  31%|███       | 4/13 [00:17<00:40,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  38%|███▊      | 5/13 [00:21<00:36,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  46%|████▌     | 6/13 [00:26<00:31,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  54%|█████▍    | 7/13 [00:29<00:25,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  62%|██████▏   | 8/13 [00:34<00:21,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  69%|██████▉   | 9/13 [00:37<00:16,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  77%|███████▋  | 10/13 [00:42<00:12,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  85%|████████▍ | 11/13 [00:44<00:07,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:  92%|█████████▏| 12/13 [00:47<00:03,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 13/13 [00:51<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n",
      "Speed: 0.0ms preprocess, 44.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\YOLOV8\\modelo8\\train2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000027B0C437850>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 1.0\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 1.0, 'metrics/accuracy_top5': 1.0, 'fitness': 1.0}\n",
       "save_dir: WindowsPath('C:/Users/dalil/Desktop/Tesis_2025/TFG---Clasificacion-de-trajes/YOLOV8/modelo8/train2')\n",
       "speed: {'preprocess': 0.0, 'inference': 44.88488211148027, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 1.0\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Con yolo8m con hiperparametros\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Cargar el modelo YOLOv8 para clasificación\n",
    "model = YOLO('yolov8m-cls.pt')\n",
    "\n",
    "# Entrenamiento con hiperparámetros ajustados\n",
    "model.train(\n",
    "    data=r\"C:\\\\Users\\\\dalil\\\\Desktop\\\\Tesis_2025\\\\TFG---Clasificacion-de-trajes\\\\YOLOV8\\\\dataset\",\n",
    "    epochs=20,  # Más épocas para mejor aprendizaje\n",
    "    imgsz=256,  # Tamaño de la imagen\n",
    "    batch=16,  # Tamaño del batch\n",
    "    lr0=0.01,  # Tasa de aprendizaje inicial\n",
    "    lrf=0.1,  # Factor de reducción de la tasa de aprendizaje\n",
    "    momentum=0.9,  # Momento de optimización\n",
    "    weight_decay=5e-4,  # Regularización L2\n",
    "    optimizer='SGD',  # Optimizador (puede ser 'AdamW' también)\n",
    "    project=r\"C:\\\\Users\\\\dalil\\\\Desktop\\\\Tesis_2025\\\\TFG---Clasificacion-de-trajes\\\\YOLOV8\\\\modelo8\",\n",
    "    patience=10,  # Número de épocas sin mejora antes de detener el entrenamiento\n",
    "    dropout=0.2,  # Tasa de dropout para prevenir overfitting\n",
    "    augment=True  # Aumentación de datos\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb302da",
   "metadata": {},
   "source": [
    "Testeo del modelo elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d6b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3250b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0574_FAN_FE.png: 256x256 inspiracion 0.90, fantasia 0.10, popular 0.00, tradicional 0.00, 107.7ms\n",
      "Speed: 12.0ms preprocess, 107.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0588_FAN_FE.png: 256x256 fantasia 1.00, popular 0.00, inspiracion 0.00, tradicional 0.00, 179.1ms\n",
      "Speed: 0.0ms preprocess, 179.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0599_FAN_FE.png: 256x256 fantasia 1.00, popular 0.00, inspiracion 0.00, tradicional 0.00, 109.3ms\n",
      "Speed: 4.5ms preprocess, 109.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0601_FAN_FE.png: 256x256 fantasia 0.71, popular 0.16, inspiracion 0.07, tradicional 0.06, 160.7ms\n",
      "Speed: 2.0ms preprocess, 160.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0623_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 106.6ms\n",
      "Speed: 4.0ms preprocess, 106.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0624_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 83.1ms\n",
      "Speed: 3.0ms preprocess, 83.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0642_FAN_FE.png: 256x256 popular 0.70, inspiracion 0.22, tradicional 0.07, fantasia 0.02, 80.4ms\n",
      "Speed: 11.3ms preprocess, 80.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0651_FAN_FE.png: 256x256 popular 0.78, fantasia 0.10, inspiracion 0.08, tradicional 0.04, 70.1ms\n",
      "Speed: 2.0ms preprocess, 70.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0673_FAN_FE.png: 256x256 fantasia 0.99, popular 0.01, inspiracion 0.00, tradicional 0.00, 84.5ms\n",
      "Speed: 4.3ms preprocess, 84.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0679_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 95.9ms\n",
      "Speed: 4.6ms preprocess, 95.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0688_FAN_FE.png: 256x256 fantasia 0.99, inspiracion 0.01, popular 0.00, tradicional 0.00, 97.2ms\n",
      "Speed: 6.8ms preprocess, 97.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0689_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 101.4ms\n",
      "Speed: 3.7ms preprocess, 101.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0726_FAN_FE.png: 256x256 fantasia 0.75, popular 0.19, inspiracion 0.06, tradicional 0.00, 97.0ms\n",
      "Speed: 2.0ms preprocess, 97.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0752_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 123.4ms\n",
      "Speed: 1.6ms preprocess, 123.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0762_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 121.4ms\n",
      "Speed: 5.6ms preprocess, 121.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0775_FAN_FE.png: 256x256 fantasia 1.00, popular 0.00, inspiracion 0.00, tradicional 0.00, 112.9ms\n",
      "Speed: 2.3ms preprocess, 112.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0781_FAN_FE.png: 256x256 fantasia 0.95, inspiracion 0.05, popular 0.00, tradicional 0.00, 99.8ms\n",
      "Speed: 15.8ms preprocess, 99.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0821_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 107.0ms\n",
      "Speed: 9.1ms preprocess, 107.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0846_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 132.5ms\n",
      "Speed: 2.0ms preprocess, 132.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0849_FAN_FE.png: 256x256 fantasia 1.00, popular 0.00, inspiracion 0.00, tradicional 0.00, 113.0ms\n",
      "Speed: 4.0ms preprocess, 113.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0860_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 103.3ms\n",
      "Speed: 3.5ms preprocess, 103.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0895_FAN_FE.png: 256x256 fantasia 1.00, popular 0.00, inspiracion 0.00, tradicional 0.00, 116.2ms\n",
      "Speed: 4.5ms preprocess, 116.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0898_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 132.1ms\n",
      "Speed: 3.8ms preprocess, 132.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0900_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 131.7ms\n",
      "Speed: 3.2ms preprocess, 131.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0904_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 110.5ms\n",
      "Speed: 0.0ms preprocess, 110.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0907_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 99.2ms\n",
      "Speed: 4.4ms preprocess, 99.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0912_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 99.3ms\n",
      "Speed: 2.0ms preprocess, 99.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0914_FAN_FE.png: 256x256 fantasia 1.00, popular 0.00, inspiracion 0.00, tradicional 0.00, 104.1ms\n",
      "Speed: 0.0ms preprocess, 104.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0923_FAN_FE.png: 256x256 fantasia 0.99, popular 0.01, inspiracion 0.00, tradicional 0.00, 76.3ms\n",
      "Speed: 2.1ms preprocess, 76.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0924_FAN_FE.png: 256x256 fantasia 0.98, popular 0.02, inspiracion 0.00, tradicional 0.00, 105.6ms\n",
      "Speed: 0.0ms preprocess, 105.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0925_FAN_FE.png: 256x256 fantasia 0.93, inspiracion 0.04, popular 0.03, tradicional 0.00, 102.9ms\n",
      "Speed: 0.0ms preprocess, 102.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0945_FAN_FE.png: 256x256 fantasia 0.98, popular 0.02, inspiracion 0.00, tradicional 0.00, 127.2ms\n",
      "Speed: 0.0ms preprocess, 127.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0954_FAN_FE.png: 256x256 fantasia 0.99, inspiracion 0.01, popular 0.00, tradicional 0.00, 98.4ms\n",
      "Speed: 2.8ms preprocess, 98.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0972_FAN_FE.png: 256x256 inspiracion 0.96, fantasia 0.04, popular 0.00, tradicional 0.00, 93.8ms\n",
      "Speed: 4.0ms preprocess, 93.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0976_FAN_FE.png: 256x256 fantasia 0.99, inspiracion 0.01, popular 0.00, tradicional 0.00, 106.1ms\n",
      "Speed: 2.0ms preprocess, 106.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0982_FAN_FE.png: 256x256 inspiracion 0.49, fantasia 0.29, popular 0.22, tradicional 0.01, 87.9ms\n",
      "Speed: 2.0ms preprocess, 87.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG0984_FAN_FE.png: 256x256 popular 0.65, fantasia 0.19, inspiracion 0.16, tradicional 0.00, 92.1ms\n",
      "Speed: 4.5ms preprocess, 92.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4217_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 118.6ms\n",
      "Speed: 2.0ms preprocess, 118.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4227_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 122.0ms\n",
      "Speed: 3.1ms preprocess, 122.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4232_FAN_FE.png: 256x256 fantasia 0.99, tradicional 0.01, inspiracion 0.00, popular 0.00, 112.4ms\n",
      "Speed: 0.0ms preprocess, 112.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4233_FAN_FE.png: 256x256 fantasia 0.99, inspiracion 0.01, popular 0.00, tradicional 0.00, 89.6ms\n",
      "Speed: 3.6ms preprocess, 89.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4240_FAN_FE.png: 256x256 fantasia 0.99, inspiracion 0.00, popular 0.00, tradicional 0.00, 85.8ms\n",
      "Speed: 1.0ms preprocess, 85.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4246_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 42.4ms\n",
      "Speed: 4.2ms preprocess, 42.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4251_FAN_FE.png: 256x256 fantasia 0.99, popular 0.01, inspiracion 0.00, tradicional 0.00, 46.2ms\n",
      "Speed: 4.0ms preprocess, 46.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4258_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 42.9ms\n",
      "Speed: 4.9ms preprocess, 42.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4285_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 43.3ms\n",
      "Speed: 3.7ms preprocess, 43.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4292_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 43.7ms\n",
      "Speed: 6.2ms preprocess, 43.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4306_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 70.1ms\n",
      "Speed: 1.7ms preprocess, 70.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4329_FAN_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, tradicional 0.00, popular 0.00, 50.4ms\n",
      "Speed: 0.0ms preprocess, 50.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\fantasia\\IMG4345_FAN_FE.png: 256x256 fantasia 0.99, inspiracion 0.01, popular 0.00, tradicional 0.00, 51.1ms\n",
      "Speed: 0.0ms preprocess, 51.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0148_INF_FE.png: 256x256 inspiracion 0.97, fantasia 0.03, popular 0.00, tradicional 0.00, 46.1ms\n",
      "Speed: 5.2ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0170_INF_FE.png: 256x256 inspiracion 0.93, fantasia 0.05, popular 0.02, tradicional 0.00, 45.5ms\n",
      "Speed: 3.8ms preprocess, 45.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0178_INF_FE.png: 256x256 inspiracion 0.95, fantasia 0.05, popular 0.00, tradicional 0.00, 52.9ms\n",
      "Speed: 4.8ms preprocess, 52.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0182_INF_FE.png: 256x256 inspiracion 1.00, fantasia 0.00, popular 0.00, tradicional 0.00, 46.4ms\n",
      "Speed: 4.8ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0189_INF_FE.png: 256x256 fantasia 0.64, inspiracion 0.36, tradicional 0.00, popular 0.00, 58.4ms\n",
      "Speed: 2.8ms preprocess, 58.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0193_INF_FE.png: 256x256 fantasia 0.50, inspiracion 0.45, popular 0.04, tradicional 0.00, 45.4ms\n",
      "Speed: 4.0ms preprocess, 45.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0194_INF_FE.png: 256x256 inspiracion 0.94, fantasia 0.03, popular 0.03, tradicional 0.00, 48.9ms\n",
      "Speed: 0.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0200_INF_FE.png: 256x256 fantasia 0.79, popular 0.14, inspiracion 0.07, tradicional 0.00, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0216_INF_FE.png: 256x256 inspiracion 0.92, popular 0.07, fantasia 0.01, tradicional 0.00, 61.4ms\n",
      "Speed: 2.9ms preprocess, 61.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0224_INF_FE.png: 256x256 fantasia 0.58, popular 0.30, inspiracion 0.12, tradicional 0.00, 42.7ms\n",
      "Speed: 6.9ms preprocess, 42.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0226_INF_FE.png: 256x256 inspiracion 0.48, fantasia 0.46, popular 0.05, tradicional 0.00, 44.3ms\n",
      "Speed: 4.8ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0246_INF_FE.png: 256x256 inspiracion 0.55, fantasia 0.36, popular 0.09, tradicional 0.00, 44.0ms\n",
      "Speed: 8.4ms preprocess, 44.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0264_INF_FE.png: 256x256 inspiracion 1.00, popular 0.00, tradicional 0.00, fantasia 0.00, 47.9ms\n",
      "Speed: 6.8ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0272_INF_FE.png: 256x256 inspiracion 0.45, fantasia 0.42, popular 0.07, tradicional 0.06, 46.5ms\n",
      "Speed: 2.7ms preprocess, 46.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0279_INF_FE.png: 256x256 inspiracion 0.58, tradicional 0.41, fantasia 0.00, popular 0.00, 46.1ms\n",
      "Speed: 4.1ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0301_INF_FE.png: 256x256 inspiracion 0.98, fantasia 0.01, tradicional 0.01, popular 0.00, 52.6ms\n",
      "Speed: 0.0ms preprocess, 52.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0307_INF_FE.png: 256x256 fantasia 0.98, tradicional 0.01, inspiracion 0.00, popular 0.00, 54.8ms\n",
      "Speed: 4.0ms preprocess, 54.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0308_INF_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0309_INF_FE.png: 256x256 fantasia 1.00, inspiracion 0.00, popular 0.00, tradicional 0.00, 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0332_INF_FE.png: 256x256 inspiracion 0.77, fantasia 0.23, tradicional 0.00, popular 0.00, 44.0ms\n",
      "Speed: 7.4ms preprocess, 44.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0348_INF_FE.png: 256x256 inspiracion 0.99, popular 0.01, fantasia 0.00, tradicional 0.00, 42.9ms\n",
      "Speed: 4.4ms preprocess, 42.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0362_INF_FE.png: 256x256 inspiracion 1.00, fantasia 0.00, popular 0.00, tradicional 0.00, 45.3ms\n",
      "Speed: 7.5ms preprocess, 45.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0379_INF_FE.png: 256x256 inspiracion 1.00, fantasia 0.00, popular 0.00, tradicional 0.00, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0387_INF_FE.png: 256x256 inspiracion 0.80, fantasia 0.20, popular 0.00, tradicional 0.00, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0388_INF_FE.png: 256x256 inspiracion 0.98, fantasia 0.02, popular 0.00, tradicional 0.00, 44.2ms\n",
      "Speed: 3.0ms preprocess, 44.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0390_INF_FE.png: 256x256 inspiracion 0.83, fantasia 0.16, popular 0.00, tradicional 0.00, 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0391_INF_FE.png: 256x256 inspiracion 0.99, fantasia 0.01, popular 0.00, tradicional 0.00, 42.9ms\n",
      "Speed: 2.4ms preprocess, 42.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0401_INF_FE.png: 256x256 inspiracion 0.97, fantasia 0.02, popular 0.01, tradicional 0.00, 42.6ms\n",
      "Speed: 3.0ms preprocess, 42.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0406_INF_FE.png: 256x256 inspiracion 1.00, fantasia 0.00, popular 0.00, tradicional 0.00, 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0450_INF_FE.png: 256x256 inspiracion 0.99, fantasia 0.01, tradicional 0.00, popular 0.00, 60.5ms\n",
      "Speed: 0.0ms preprocess, 60.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0451_INF_FE.png: 256x256 fantasia 0.52, inspiracion 0.48, tradicional 0.00, popular 0.00, 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0454_INF_FE.png: 256x256 inspiracion 1.00, fantasia 0.00, popular 0.00, tradicional 0.00, 46.4ms\n",
      "Speed: 4.7ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0480_INF_FE.png: 256x256 inspiracion 0.90, fantasia 0.09, popular 0.01, tradicional 0.00, 47.4ms\n",
      "Speed: 6.5ms preprocess, 47.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0485_INF_FE.png: 256x256 inspiracion 0.98, popular 0.01, fantasia 0.01, tradicional 0.00, 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0486_INF_FE.png: 256x256 inspiracion 0.51, fantasia 0.45, popular 0.04, tradicional 0.00, 43.9ms\n",
      "Speed: 2.6ms preprocess, 43.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0487_INF_FE.png: 256x256 inspiracion 0.57, fantasia 0.26, popular 0.16, tradicional 0.01, 60.0ms\n",
      "Speed: 0.0ms preprocess, 60.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0494_INF_FE.png: 256x256 tradicional 0.98, inspiracion 0.01, fantasia 0.01, popular 0.00, 44.4ms\n",
      "Speed: 2.7ms preprocess, 44.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0502_INF_FE.png: 256x256 inspiracion 0.65, fantasia 0.33, tradicional 0.01, popular 0.01, 42.3ms\n",
      "Speed: 2.4ms preprocess, 42.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0509_INF_FE.png: 256x256 inspiracion 0.72, fantasia 0.25, tradicional 0.03, popular 0.00, 58.5ms\n",
      "Speed: 8.4ms preprocess, 58.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0520_INF_FE.png: 256x256 inspiracion 0.96, fantasia 0.04, tradicional 0.00, popular 0.00, 46.3ms\n",
      "Speed: 2.5ms preprocess, 46.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0522_INF_FE.png: 256x256 inspiracion 1.00, fantasia 0.00, popular 0.00, tradicional 0.00, 44.3ms\n",
      "Speed: 4.0ms preprocess, 44.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0533_INF_FE.png: 256x256 inspiracion 0.63, fantasia 0.37, popular 0.00, tradicional 0.00, 36.3ms\n",
      "Speed: 4.8ms preprocess, 36.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0538_INF_FE.png: 256x256 inspiracion 1.00, fantasia 0.00, popular 0.00, tradicional 0.00, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0873_FAN_FE.png: 256x256 inspiracion 0.46, popular 0.30, fantasia 0.24, tradicional 0.00, 45.9ms\n",
      "Speed: 3.6ms preprocess, 45.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0874_FAN_FE.png: 256x256 popular 0.60, inspiracion 0.29, fantasia 0.10, tradicional 0.01, 57.2ms\n",
      "Speed: 2.0ms preprocess, 57.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0881_FAN_FE.png: 256x256 inspiracion 0.93, fantasia 0.07, popular 0.00, tradicional 0.00, 40.7ms\n",
      "Speed: 4.0ms preprocess, 40.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0883_FAN_FE.png: 256x256 inspiracion 0.99, fantasia 0.01, popular 0.00, tradicional 0.00, 44.7ms\n",
      "Speed: 3.6ms preprocess, 44.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG0959_FAN_FE.png: 256x256 fantasia 0.94, inspiracion 0.04, popular 0.02, tradicional 0.00, 44.4ms\n",
      "Speed: 7.6ms preprocess, 44.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG3546_INF_FP.jpg: 256x256 inspiracion 1.00, fantasia 0.00, tradicional 0.00, popular 0.00, 32.3ms\n",
      "Speed: 26.1ms preprocess, 32.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\inspiracion\\IMG4354_FAN_FE.png: 256x256 fantasia 0.98, inspiracion 0.02, popular 0.00, tradicional 0.00, 47.5ms\n",
      "Speed: 6.7ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 193824.png: 256x256 popular 0.56, fantasia 0.44, inspiracion 0.00, tradicional 0.00, 54.6ms\n",
      "Speed: 0.0ms preprocess, 54.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 193922.png: 256x256 popular 0.97, fantasia 0.03, inspiracion 0.00, tradicional 0.00, 43.1ms\n",
      "Speed: 5.4ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 194003.png: 256x256 popular 0.98, fantasia 0.01, inspiracion 0.00, tradicional 0.00, 43.2ms\n",
      "Speed: 2.0ms preprocess, 43.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 194033.png: 256x256 popular 1.00, fantasia 0.00, inspiracion 0.00, tradicional 0.00, 57.9ms\n",
      "Speed: 3.9ms preprocess, 57.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 194220.png: 256x256 fantasia 0.55, inspiracion 0.38, popular 0.07, tradicional 0.00, 46.5ms\n",
      "Speed: 4.0ms preprocess, 46.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 194239.png: 256x256 fantasia 0.65, popular 0.24, inspiracion 0.10, tradicional 0.00, 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 194257.png: 256x256 fantasia 0.78, popular 0.15, inspiracion 0.06, tradicional 0.01, 47.0ms\n",
      "Speed: 8.7ms preprocess, 47.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 194530.png: 256x256 inspiracion 0.99, popular 0.01, tradicional 0.00, fantasia 0.00, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 194740.png: 256x256 inspiracion 1.00, fantasia 0.00, popular 0.00, tradicional 0.00, 47.7ms\n",
      "Speed: 2.2ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 194835.png: 256x256 inspiracion 0.91, popular 0.06, fantasia 0.03, tradicional 0.00, 47.6ms\n",
      "Speed: 8.1ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 200052.png: 256x256 popular 0.38, inspiracion 0.34, fantasia 0.23, tradicional 0.05, 60.8ms\n",
      "Speed: 5.4ms preprocess, 60.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\Captura de pantalla 2025-03-03 200131.png: 256x256 fantasia 0.89, popular 0.06, inspiracion 0.03, tradicional 0.01, 45.5ms\n",
      "Speed: 4.7ms preprocess, 45.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0082_POP_FE.png: 256x256 fantasia 0.98, popular 0.02, inspiracion 0.00, tradicional 0.00, 51.8ms\n",
      "Speed: 0.0ms preprocess, 51.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0083_POP_FE.png: 256x256 popular 0.98, inspiracion 0.02, fantasia 0.00, tradicional 0.00, 43.9ms\n",
      "Speed: 6.7ms preprocess, 43.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0090_POP_FE.png: 256x256 popular 0.98, inspiracion 0.02, tradicional 0.00, fantasia 0.00, 46.3ms\n",
      "Speed: 4.0ms preprocess, 46.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0095_POP_FE.png: 256x256 popular 0.97, fantasia 0.03, inspiracion 0.00, tradicional 0.00, 46.2ms\n",
      "Speed: 4.0ms preprocess, 46.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0115_POP_FE.png: 256x256 tradicional 0.62, inspiracion 0.30, fantasia 0.05, popular 0.04, 43.0ms\n",
      "Speed: 4.0ms preprocess, 43.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0126_POP_FE.png: 256x256 popular 0.95, inspiracion 0.05, fantasia 0.00, tradicional 0.00, 48.0ms\n",
      "Speed: 0.0ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0138_POP_FE.png: 256x256 fantasia 0.94, popular 0.06, inspiracion 0.00, tradicional 0.00, 43.8ms\n",
      "Speed: 1.7ms preprocess, 43.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0144_POP_FE.png: 256x256 popular 0.77, fantasia 0.17, inspiracion 0.05, tradicional 0.00, 48.0ms\n",
      "Speed: 0.0ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0515_INF_FE.png: 256x256 popular 0.67, fantasia 0.24, tradicional 0.08, inspiracion 0.02, 46.9ms\n",
      "Speed: 3.9ms preprocess, 46.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0712_FAN_FE.png: 256x256 popular 0.54, fantasia 0.46, inspiracion 0.00, tradicional 0.00, 46.6ms\n",
      "Speed: 5.9ms preprocess, 46.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG0713_FAN_FE.png: 256x256 fantasia 0.89, popular 0.11, inspiracion 0.00, tradicional 0.00, 48.8ms\n",
      "Speed: 6.5ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2441_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, tradicional 0.00, fantasia 0.00, 40.6ms\n",
      "Speed: 106.9ms preprocess, 40.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2486_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, tradicional 0.00, fantasia 0.00, 45.5ms\n",
      "Speed: 105.5ms preprocess, 45.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2495_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, tradicional 0.00, fantasia 0.00, 41.5ms\n",
      "Speed: 91.5ms preprocess, 41.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2528_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, fantasia 0.00, tradicional 0.00, 45.4ms\n",
      "Speed: 100.6ms preprocess, 45.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2554_POP_FP.jpeg: 256x256 popular 1.00, tradicional 0.00, fantasia 0.00, inspiracion 0.00, 55.7ms\n",
      "Speed: 85.7ms preprocess, 55.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2573_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, tradicional 0.00, fantasia 0.00, 40.8ms\n",
      "Speed: 83.2ms preprocess, 40.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2595_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, fantasia 0.00, tradicional 0.00, 31.9ms\n",
      "Speed: 88.2ms preprocess, 31.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2600_POP_FP.jpeg: 256x256 popular 1.00, tradicional 0.00, inspiracion 0.00, fantasia 0.00, 36.8ms\n",
      "Speed: 78.1ms preprocess, 36.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2607_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, fantasia 0.00, tradicional 0.00, 62.8ms\n",
      "Speed: 80.4ms preprocess, 62.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2616_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, fantasia 0.00, tradicional 0.00, 65.5ms\n",
      "Speed: 74.3ms preprocess, 65.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2633_POP_FP.jpeg: 256x256 popular 1.00, fantasia 0.00, inspiracion 0.00, tradicional 0.00, 44.4ms\n",
      "Speed: 87.1ms preprocess, 44.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2661_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, tradicional 0.00, fantasia 0.00, 54.3ms\n",
      "Speed: 80.9ms preprocess, 54.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2670_POP_FP.jpeg: 256x256 popular 1.00, inspiracion 0.00, fantasia 0.00, tradicional 0.00, 49.9ms\n",
      "Speed: 75.4ms preprocess, 49.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2686_POP_FP.jpeg: 256x256 popular 1.00, tradicional 0.00, inspiracion 0.00, fantasia 0.00, 51.5ms\n",
      "Speed: 88.6ms preprocess, 51.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2694_POP_FP.jpeg: 256x256 popular 1.00, fantasia 0.00, tradicional 0.00, inspiracion 0.00, 44.9ms\n",
      "Speed: 87.6ms preprocess, 44.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2726_POP_FP.jpeg: 256x256 popular 1.00, tradicional 0.00, inspiracion 0.00, fantasia 0.00, 40.0ms\n",
      "Speed: 90.9ms preprocess, 40.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2736_POP_FP.JPG: 256x256 popular 1.00, tradicional 0.00, inspiracion 0.00, fantasia 0.00, 39.2ms\n",
      "Speed: 141.2ms preprocess, 39.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2755_POP_FP.JPG: 256x256 popular 1.00, inspiracion 0.00, tradicional 0.00, fantasia 0.00, 55.3ms\n",
      "Speed: 126.0ms preprocess, 55.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2761_POP_FP.JPG: 256x256 popular 1.00, inspiracion 0.00, tradicional 0.00, fantasia 0.00, 40.0ms\n",
      "Speed: 134.7ms preprocess, 40.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2768_POP_FP.JPG: 256x256 popular 1.00, inspiracion 0.00, fantasia 0.00, tradicional 0.00, 42.6ms\n",
      "Speed: 142.0ms preprocess, 42.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2780_POP_FP.JPG: 256x256 popular 1.00, tradicional 0.00, fantasia 0.00, inspiracion 0.00, 40.9ms\n",
      "Speed: 128.6ms preprocess, 40.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2791_POP_FP.JPG: 256x256 popular 1.00, inspiracion 0.00, fantasia 0.00, tradicional 0.00, 45.4ms\n",
      "Speed: 121.4ms preprocess, 45.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2814_POP_FP.JPG: 256x256 popular 1.00, tradicional 0.00, fantasia 0.00, inspiracion 0.00, 60.1ms\n",
      "Speed: 135.3ms preprocess, 60.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG2821_POP_FP.JPG: 256x256 popular 1.00, tradicional 0.00, inspiracion 0.00, fantasia 0.00, 46.0ms\n",
      "Speed: 124.6ms preprocess, 46.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG4311_FAN_FE.png: 256x256 popular 0.94, fantasia 0.03, inspiracion 0.03, tradicional 0.00, 98.9ms\n",
      "Speed: 4.0ms preprocess, 98.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\IMG4391_FAN_FE.png: 256x256 popular 0.62, fantasia 0.36, inspiracion 0.01, tradicional 0.00, 82.2ms\n",
      "Speed: 4.0ms preprocess, 82.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\popular\\WhatsApp Image 2025-03-03 at 19.52.39.jpeg: 256x256 popular 0.72, fantasia 0.28, tradicional 0.00, inspiracion 0.00, 41.1ms\n",
      "Speed: 13.6ms preprocess, 41.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0005_TRA_FE.png: 256x256 tradicional 0.67, inspiracion 0.32, popular 0.01, fantasia 0.00, 61.3ms\n",
      "Speed: 2.0ms preprocess, 61.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0007_TRA_FE.png: 256x256 tradicional 1.00, fantasia 0.00, inspiracion 0.00, popular 0.00, 38.7ms\n",
      "Speed: 4.3ms preprocess, 38.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0023_TRA_FE.png: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 57.8ms\n",
      "Speed: 5.5ms preprocess, 57.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0026_TRA_FE.png: 256x256 tradicional 0.99, fantasia 0.01, inspiracion 0.00, popular 0.00, 43.7ms\n",
      "Speed: 4.3ms preprocess, 43.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0036_TRA_FE.png: 256x256 inspiracion 0.44, fantasia 0.41, tradicional 0.11, popular 0.05, 47.9ms\n",
      "Speed: 2.2ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0041_TRA_FE.png: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0042_TRA_FE.png: 256x256 tradicional 0.96, inspiracion 0.04, fantasia 0.00, popular 0.00, 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0046_TRA_FE.png: 256x256 tradicional 0.84, fantasia 0.16, inspiracion 0.00, popular 0.00, 47.9ms\n",
      "Speed: 3.9ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0059_TRA_FE.png: 256x256 inspiracion 0.54, tradicional 0.45, fantasia 0.00, popular 0.00, 44.1ms\n",
      "Speed: 3.4ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0061_TRA_FE.png: 256x256 tradicional 0.76, inspiracion 0.24, fantasia 0.00, popular 0.00, 44.1ms\n",
      "Speed: 1.7ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0062_TRA_FE.png: 256x256 tradicional 1.00, fantasia 0.00, inspiracion 0.00, popular 0.00, 43.8ms\n",
      "Speed: 2.9ms preprocess, 43.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG0068_TRA_FE.png: 256x256 inspiracion 0.58, fantasia 0.19, popular 0.13, tradicional 0.09, 54.3ms\n",
      "Speed: 2.3ms preprocess, 54.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1008_TRA_FP.jpeg: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 43.1ms\n",
      "Speed: 88.4ms preprocess, 43.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1026_TRA_FP.jpeg: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 42.1ms\n",
      "Speed: 87.6ms preprocess, 42.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1039_TRA_FP.jpeg: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 37.5ms\n",
      "Speed: 87.6ms preprocess, 37.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1061_TRA_FP.jpeg: 256x256 tradicional 1.00, inspiracion 0.00, popular 0.00, fantasia 0.00, 38.3ms\n",
      "Speed: 88.1ms preprocess, 38.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1067_TRA_FP.jpeg: 256x256 tradicional 1.00, popular 0.00, inspiracion 0.00, fantasia 0.00, 44.1ms\n",
      "Speed: 84.7ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1074_TRA_FP.jpeg: 256x256 tradicional 1.00, fantasia 0.00, inspiracion 0.00, popular 0.00, 41.6ms\n",
      "Speed: 85.6ms preprocess, 41.6ms inference, 3.2ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1122_TRA_FP.jpeg: 256x256 tradicional 1.00, inspiracion 0.00, popular 0.00, fantasia 0.00, 53.0ms\n",
      "Speed: 87.3ms preprocess, 53.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1147_TRA_FP.jpeg: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 43.5ms\n",
      "Speed: 93.4ms preprocess, 43.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1169_TRA_FP.JPG: 256x256 tradicional 1.00, fantasia 0.00, inspiracion 0.00, popular 0.00, 46.4ms\n",
      "Speed: 123.5ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1195_TRA_FP.JPG: 256x256 tradicional 1.00, fantasia 0.00, inspiracion 0.00, popular 0.00, 44.8ms\n",
      "Speed: 117.4ms preprocess, 44.8ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1200_TRA_FP.JPG: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 46.7ms\n",
      "Speed: 110.0ms preprocess, 46.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1236_TRA_FP.JPG: 256x256 tradicional 1.00, fantasia 0.00, popular 0.00, inspiracion 0.00, 48.1ms\n",
      "Speed: 124.7ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1240_TRA_FP.JPG: 256x256 tradicional 1.00, fantasia 0.00, inspiracion 0.00, popular 0.00, 46.1ms\n",
      "Speed: 138.5ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1248_TRA_FP.JPG: 256x256 tradicional 1.00, fantasia 0.00, popular 0.00, inspiracion 0.00, 43.0ms\n",
      "Speed: 124.1ms preprocess, 43.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1255_TRA_FP.JPG: 256x256 tradicional 1.00, fantasia 0.00, inspiracion 0.00, popular 0.00, 46.1ms\n",
      "Speed: 137.3ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1274_TRA_FP.JPG: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 47.6ms\n",
      "Speed: 114.8ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1291_TRA_FP.JPG: 256x256 tradicional 1.00, inspiracion 0.00, popular 0.00, fantasia 0.00, 45.6ms\n",
      "Speed: 125.4ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1306_TRA_FP.JPG: 256x256 tradicional 1.00, inspiracion 0.00, popular 0.00, fantasia 0.00, 55.3ms\n",
      "Speed: 120.9ms preprocess, 55.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1342_TRA_FP.jpg: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 91.7ms\n",
      "Speed: 80.9ms preprocess, 91.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "\n",
      "image 1/1 C:\\Users\\dalil\\Desktop\\Tesis_2025\\Tutorial_yolo_\\Tutorial_yolo\\dataset\\test\\tradicional\\IMG1373_TRA_FP.jpg: 256x256 tradicional 1.00, inspiracion 0.00, fantasia 0.00, popular 0.00, 100.0ms\n",
      "Speed: 11.3ms preprocess, 100.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Predicciones guardadas en C:\\Users\\dalil\\Desktop\\Tesis_2025\\TFG---Clasificacion-de-trajes\\pruebas\\predicciones\\predicciones_octavo_modelo.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalil\\AppData\\Local\\Temp\\ipykernel_11372\\3059967061.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"prediccion\"] = predicciones\n"
     ]
    }
   ],
   "source": [
    "# Configuración\n",
    "modelo_path = \"C:\\\\Users\\\\dalil\\\\Desktop\\\\Tesis_2025\\\\TFG---Clasificacion-de-trajes\\\\YOLOV8\\\\modelo8\\\\train\\\\weights\\\\best.pt\"\n",
    "csv_path = \"C:\\\\Users\\\\dalil\\\\Desktop\\\\Tesis_2025\\\\TFG---Clasificacion-de-trajes\\\\pruebas\\\\dataset_labels.csv\"\n",
    "output_csv = \"C:\\\\Users\\\\dalil\\\\Desktop\\\\Tesis_2025\\\\TFG---Clasificacion-de-trajes\\\\pruebas\\\\predicciones\\\\predicciones_octavo_modelo.csv\" \n",
    "\n",
    "# Cargar el modelo YOLO\n",
    "model = YOLO(modelo_path)\n",
    "\n",
    "# Cargar dataset CSV\n",
    "df = pd.read_csv(csv_path, header=None, names=[\"link_imagen\", \"categoria\", \"split\"])\n",
    "\n",
    "# Filtrar solo las imágenes de prueba\n",
    "df_test = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "# Realizar predicciones\n",
    "predicciones = []\n",
    "for img_path in df_test[\"link_imagen\"]:\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Archivo no encontrado: {img_path}\")\n",
    "    else:\n",
    "        resultados = model(img_path)  # Inferencia con YOLO\n",
    "        prediccion = resultados[0].names[int(resultados[0].probs.top1)]  # Obtener la clase más probable\n",
    "        predicciones.append(prediccion)\n",
    "\n",
    "# Agregar la columna de predicción al DataFrame\n",
    "df_test[\"prediccion\"] = predicciones\n",
    "\n",
    "# Guardar nuevo CSV con predicciones\n",
    "df_test.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Predicciones guardadas en {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2fe89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar el CSV con las predicciones\n",
    "ruta_csv = output_csv\n",
    "df = pd.read_csv(ruta_csv)\n",
    "\n",
    "# Extraer etiquetas reales y predichas\n",
    "y_true = df[\"categoria\"].tolist()   # Etiquetas reales\n",
    "y_pred = df[\"prediccion\"].tolist()  # Etiquetas predichas\n",
    "\n",
    "# Obtener las clases únicas (en caso de que haya errores en el CSV, eliminamos duplicados)\n",
    "clases = sorted(set(y_true + y_pred))\n",
    "\n",
    "# Generar la matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred, labels=clases)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clases)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Generar reporte de métricas\n",
    "reporte = classification_report(y_true, y_pred, labels=clases, output_dict=True)\n",
    "\n",
    "# Convertir a DataFrame para visualizar mejor\n",
    "df_reporte = pd.DataFrame(reporte).transpose()\n",
    "\n",
    "# Mostrar métricas por categoría\n",
    "print(df_reporte)\n",
    "\n",
    "# Opcional: Guardar en un archivo CSV\n",
    "df_reporte.to_csv(\"reporte_metricas.csv\", index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
